This project an AI neural network written from scratch without any existing ai libraries. 
Behavior will be similar to TensorFlow or PyTorch.
Features will include neurons with weights and activation functions. Training via gradient descent back propagation.

This will be a feed forward network utilizing a perceptron architecture. 
The perceptron will function as a binary classifier that makes predictions based on a linear combination of input features. It takes one or more weighted inputs and returns a single binary output, either 1 or 0 

Adding these features:

Architecture Definability. 
Be able to specify the layers (input hidden output) and the activation function in each layer (ex relu)

Optimizer algo - to adjust the weights of the neural network to minimize the loss function. It determines how the model updates its weights based on the gradients computed during backpropagation.

Loss function -  measures how well the model's predictions match the actual target values. It quantifies the difference between the predicted outputs and the true outputs. The optimizer uses this loss to update the model's weights.



